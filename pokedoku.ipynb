{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square 1 (psychic, fire): Victini\n",
      "Square 2 (MIDDLE EVOLUTION, fire): Charmeleon\n",
      "Square 3 (ground, fire): Numel\n",
      "Square 4 (psychic, normal): Girafarig\n",
      "Square 5 (MIDDLE EVOLUTION, normal): Pidgeotto\n",
      "Square 6 (ground, normal): Diggersby\n",
      "Square 7 (psychic, PALDEA + AREA ZERO DLC): Armarouge\n",
      "Square 8 (MIDDLE EVOLUTION, PALDEA + AREA ZERO DLC): Floragato\n",
      "Square 9 (ground, PALDEA + AREA ZERO DLC): Wooper\n"
     ]
    }
   ],
   "source": [
    "# Project created with the intent of developing my programming skills\n",
    "# Pokedoku Solver\n",
    "\n",
    "# Libraries used: Selenium, bs4, pandas, time\n",
    "# Selenium is used for web scraping, since pokedoku is a dynamic website, requests didn't work\n",
    "# bs4 is utilized for html parsing\n",
    "# pandas is used for fetching data from the csv file\n",
    "# time is used to ensure all necessary data is scrapped\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--headless') # Runs the browser in the background without opening a window\n",
    "\n",
    "# Ensures the updated version of ChromeDriverManager is installed and creates a Selenium Service instance to run it\n",
    "\n",
    "service = Service(ChromeDriverManager().install()) \n",
    "\n",
    "# Launches Google Chrome using the service\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "url = 'https://pokedoku.com/' # The website link that's scrapped\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html = driver.page_source\n",
    "driver.quit() # Ends the service once the data has been scrapped\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser') # Parses the HTML file so the necessary data can be easily accessed\n",
    "\n",
    "# To be able to solve the puzzle, we'll need a list with each square's criteria, that means we'll need each square's data in order,\n",
    "# from left to right, top to bottom. However, some criteria are saved in the HTML as images, while others are saved as text, making\n",
    "# it difficult to arrange them in the necessary order.\n",
    "\n",
    "images = []\n",
    "\n",
    "image_div = soup.find_all('div', class_='css-1ciybbs') # Saves all image criteria in a list\n",
    "for div in image_div:\n",
    "    imgs = div.find_all('img', alt=True)\n",
    "    for img in imgs:\n",
    "        images.append(img['alt'])\n",
    "\n",
    "texts = []\n",
    "\n",
    "text_div = soup.find_all('div', class_='css-vywf8m') # Saves all text criteria in a list\n",
    "for div in text_div:\n",
    "    headers = div.find_all('h2', class_='chakra-heading css-tzo4a1')\n",
    "    if headers:\n",
    "        combined_text = ' '.join([header.get_text() for header in headers])\n",
    "        texts.append(combined_text)\n",
    "\n",
    "# The criteria we want are now saved, but due to being in two different lists, they are very likely out of order, so we'll look \n",
    "# through the HTML file again, with a broader range, and if the element matches one of the elements present in one of the lists, \n",
    "# then it'll save it in the criteria list, now in the proper order\n",
    "\n",
    "criteria = []\n",
    "seen = set()\n",
    "\n",
    "for element in soup.find_all(['img', 'h2']): \n",
    "    if element.name == 'img' and element.get('alt'):\n",
    "        if element.get('alt') in images:\n",
    "            value = element['alt']\n",
    "            if value not in seen:\n",
    "                criteria.append(value)\n",
    "                seen.add(value)\n",
    "    elif element.name == 'h2' and 'chakra-heading' in element.get('class', []):\n",
    "        parent_div = element.find_parent('div', class_='css-vywf8m')\n",
    "        if parent_div:\n",
    "            h2_texts = [header.get_text() for header in parent_div.find_all('h2', class_='chakra-heading')]\n",
    "            combined_text = ' '.join(h2_texts).strip()\n",
    "            if combined_text in texts:\n",
    "                if combined_text not in seen:\n",
    "                    criteria.append(combined_text)\n",
    "                    seen.add(combined_text)\n",
    "\n",
    "# Now we assign the proper criteria to each of the squares, which will then help browse the csv file\n",
    "\n",
    "first_square = [criteria[0], criteria[3]]\n",
    "second_square = [criteria[1], criteria[3]]\n",
    "third_square = [criteria[2], criteria[3]]\n",
    "fourth_square = [criteria[0], criteria[4]]\n",
    "fifth_square = [criteria[1], criteria[4]]\n",
    "sixth_square = [criteria[2], criteria[4]]\n",
    "seventh_square = [criteria[0], criteria[5]]\n",
    "eighth_square = [criteria[1], criteria[5]]\n",
    "ninth_square = [criteria[2], criteria[5]]\n",
    "\n",
    "df = pd.read_csv('pokemon.csv')\n",
    "\n",
    "criteria_list = [\n",
    "    first_square, \n",
    "    second_square,\n",
    "    third_square,\n",
    "    fourth_square,\n",
    "    fifth_square,\n",
    "    sixth_square,\n",
    "    seventh_square,\n",
    "    eighth_square,\n",
    "    ninth_square\n",
    "]\n",
    "\n",
    "# Function created to check the lines of the dataframe, and see if the line matches the criteria in each square, if so, it attaches \n",
    "# it to a dictionary\n",
    "\n",
    "def row_matches(row, search_criteria):\n",
    "    row_values = row.astype(str).str.lower().tolist()\n",
    "    return all(term.lower() in row_values for term in search_criteria)\n",
    "\n",
    "\n",
    "# Finally, it goes through each square and their criteria, finds the first row in the dataframe that matches it, and attaches it\n",
    "# to a dictionary, giving us the answers to the puzzle\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i, search_criteria in enumerate(criteria_list, start=1):\n",
    "    matching_row = df[df.apply(lambda row: row_matches(row, search_criteria), axis=1)].head(1)\n",
    "    if not matching_row.empty:\n",
    "        results[f'Square {i} ({', '.join(search_criteria)})'] = matching_row.iloc[0]['Name']\n",
    "    else:\n",
    "        results[f'Square {i} ({', '.join(search_criteria)})'] = 'No Match Found'\n",
    "\n",
    "for key, value in results.items():\n",
    "    print(f'{key}: {value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
